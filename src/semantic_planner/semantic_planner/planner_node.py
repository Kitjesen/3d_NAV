"""
semantic_planner_node â€” è¯­ä¹‰è§„åˆ’ ROS2 èŠ‚ç‚¹ (è®ºæ–‡çº§å®Œæ•´ç‰ˆ)

å‚è€ƒè®ºæ–‡:
  2026 å‰æ²¿:
  - VLingNav (arXiv 2601.08665): AdaCoT åŒè¿›ç¨‹æ¨ç† â†’ Fast/Slow è·¯å¾„
  - OmniNav (ICLR 2026): ç»Ÿä¸€å¯¼èˆª + Fast-Slow ç³»ç»Ÿ 5Hz
  - AdaNav (ICLR 2026): ä¸ç¡®å®šæ€§è‡ªé€‚åº”æ¨ç†æ·±åº¦
  - CompassNav (ICLR 2026): å¼ºåŒ–å¾®è°ƒ + Gap-Aware å¥–åŠ±

  2025:
  - ESCA/SGCLIP (NeurIPS 2025): é€‰æ‹©æ€§ Grounding â†’ åœºæ™¯å›¾è¿‡æ»¤
  - MTU3D (ICCV 2025): ç»Ÿä¸€ Grounding + Frontier é€‰æ‹©
  - MSGNav (2025): å¤šæ¨¡æ€ 3D åœºæ™¯å›¾
  - OpenFrontier (2025): FrontierNet + VLM é›¶æ ·æœ¬
  - OrionNav (2025): å››è¶³ + è¯­ä¹‰åœºæ™¯å›¾

  2024 åŸºç¡€:
  - SG-Nav (NeurIPS 2024): å±‚æ¬¡åœºæ™¯å›¾ + LLM æ¨ç†
  - SayCan (Google, 2022): å­ç›®æ ‡åˆ†è§£
  - LOVON (2024): åŠ¨ä½œåŸè¯­ + ç›®æ ‡éªŒè¯
  - VLFM (2023): Frontier è¯„åˆ†æ¢ç´¢
  - VLMnav (2024): VLM Vision grounding
  - L3MVN (ICRA 2024): æ‹“æ‰‘è®°å¿†

æ ¸å¿ƒæµç¨‹:
  1. æ¥æ”¶æŒ‡ä»¤ â†’ ä»»åŠ¡åˆ†è§£ (SayCan)
  2. å¯¹æ¯ä¸ªå­ç›®æ ‡:
     a. FIND:        æŸ¥åœºæ™¯å›¾, CLIP åŒ¹é…
     b. NAVIGATE:    å‘å¸ƒç›®æ ‡ PoseStamped
     c. LOOK_AROUND: åŸåœ°æ‰«æ (LOVON)
     d. APPROACH:    å‡é€Ÿæ¥è¿‘
     e. VERIFY:      VLM è§†è§‰éªŒè¯ (LOVON + VLMnav)
     f. EXPLORE:     Frontier è¯„åˆ† (VLFM) + æ‹“æ‰‘è®°å¿† (L3MVN)
     g. BACKTRACK:   æ‹“æ‰‘è®°å¿†å›æº¯ (LOVON)
  3. å­ç›®æ ‡å¤±è´¥ â†’ é‡è¯•æˆ–è·³åˆ°ä¸‹ä¸€ä¸ª
  4. å…¨éƒ¨å®Œæˆ â†’ ä»»åŠ¡æˆåŠŸ

è®¢é˜…:
  - instruction  (std_msgs/String, JSON)
  - scene_graph  (std_msgs/String, JSON)
  - odometry     (nav_msgs/Odometry)
  - /camera/color/image_raw (sensor_msgs/Image, å¯é€‰)
  - /nav/semantic/cancel (std_msgs/String, ä»»åŠ¡å–æ¶ˆ)

å‘å¸ƒ:
  - resolved_goal (geometry_msgs/PoseStamped)
  - cmd_vel       (geometry_msgs/Twist, ç›¸å¯¹è¯é¢˜å)
  - status        (std_msgs/String, JSON)
"""

import asyncio
import json
import math
import re
import threading
import time
import traceback
from enum import Enum
from typing import Optional, Dict

import numpy as np
import rclpy
from rclpy.node import Node
from rclpy.action import ActionClient
from rclpy.action.client import ClientGoalHandle

from geometry_msgs.msg import PoseStamped, Twist
from nav_msgs.msg import Odometry, OccupancyGrid
from sensor_msgs.msg import Image
from std_msgs.msg import String

# B5: Nav2 NavigateToPose action
try:
    from nav2_msgs.action import NavigateToPose
    _HAS_NAV2 = True
except ImportError:
    _HAS_NAV2 = False

from .llm_client import LLMConfig
from .goal_resolver import GoalResolver, GoalResult
from .task_decomposer import (
    TaskDecomposer, TaskPlan, SubGoal,
    SubGoalAction, SubGoalStatus,
)
from .topological_memory import TopologicalMemory
from .action_executor import ActionExecutor, ActionCommand
from .frontier_scorer import FrontierScorer
from .exploration_strategy import generate_frontier_goal, extract_frontier_scene_data
from .sgnav_reasoner import SGNavReasoner, FrontierSelection
from .voi_scheduler import VoIScheduler, VoIConfig, SchedulerState, SchedulerAction
from .implicit_fsm_policy import (
    ImplicitFSMPolicy,
    ImplicitFSMObservation,
)


class PlannerState(Enum):
    """è§„åˆ’å™¨çŠ¶æ€ã€‚"""
    IDLE = "idle"
    DECOMPOSING = "decomposing"
    RESOLVING = "resolving"
    NAVIGATING = "navigating"
    LOOKING_AROUND = "looking_around"
    APPROACHING = "approaching"
    VERIFYING = "verifying"
    EXPLORING = "exploring"
    BACKTRACKING = "backtracking"
    REPLANNING = "replanning"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"  # F1: ä»»åŠ¡å–æ¶ˆçŠ¶æ€


class SemanticPlannerNode(Node):
    """è¯­ä¹‰è§„åˆ’ ROS2 èŠ‚ç‚¹ (è®ºæ–‡çº§å®Œæ•´ç‰ˆ)ã€‚"""

    def __init__(self):
        super().__init__("semantic_planner_node")

        # â”€â”€ å‚æ•°å£°æ˜ â”€â”€
        # ä¸» LLM
        self.declare_parameter("llm.backend", "openai")
        self.declare_parameter("llm.model", "gpt-4o-mini")
        self.declare_parameter("llm.api_key_env", "OPENAI_API_KEY")
        self.declare_parameter("llm.timeout_sec", 10.0)
        self.declare_parameter("llm.max_retries", 2)
        self.declare_parameter("llm.temperature", 0.2)

        # å¤‡ç”¨ LLM
        self.declare_parameter("llm_fallback.backend", "qwen")
        self.declare_parameter("llm_fallback.model", "qwen-turbo")
        self.declare_parameter("llm_fallback.api_key_env", "DASHSCOPE_API_KEY")
        self.declare_parameter("llm_fallback.timeout_sec", 15.0)
        self.declare_parameter("llm_fallback.max_retries", 1)

        # ç›®æ ‡è§£æ
        self.declare_parameter("goal_resolution.confidence_threshold", 0.6)
        self.declare_parameter("goal_resolution.replan_on_failure", True)
        self.declare_parameter("goal_resolution.max_replan_attempts", 3)
        self.declare_parameter("goal_resolution.fast_path_threshold", 0.75)

        # èåˆæƒé‡ (C1, C2 å‚æ•°åŒ–)
        self.declare_parameter("fusion.weight_label_match", 0.35)
        self.declare_parameter("fusion.weight_clip_sim", 0.35)
        self.declare_parameter("fusion.weight_detector_score", 0.15)
        self.declare_parameter("fusion.weight_spatial_hint", 0.15)
        self.declare_parameter("fusion.no_clip_weight_label", 0.55)
        self.declare_parameter("fusion.no_clip_weight_detector", 0.25)
        self.declare_parameter("fusion.no_clip_weight_spatial", 0.20)
        self.declare_parameter("fusion.detector_count_normalize", 3)

        # æ¢ç´¢ç­–ç•¥
        self.declare_parameter("exploration.enable", True)
        self.declare_parameter("exploration.strategy", "frontier")
        self.declare_parameter("exploration.max_explore_steps", 20)
        self.declare_parameter("exploration.step_distance", 2.0)
        self.declare_parameter("exploration.costmap_topic", "/nav/costmap")
        self.declare_parameter("exploration.frontier_score_threshold", 0.2)
        self.declare_parameter("exploration.frontier_min_size", 5)
        self.declare_parameter("exploration.frontier_max_count", 10)
        self.declare_parameter("exploration.frontier_cluster_radius_cells", 3)
        self.declare_parameter("exploration.frontier_distance_weight", 0.2)
        self.declare_parameter("exploration.frontier_novelty_weight", 0.3)
        self.declare_parameter("exploration.frontier_language_weight", 0.2)
        self.declare_parameter("exploration.frontier_grounding_weight", 0.3)
        # C6: frontier è¯„åˆ†é˜ˆå€¼å‚æ•°åŒ– (ablation å®éªŒä¾èµ–)
        self.declare_parameter("exploration.frontier_novelty_distance", 5.0)
        self.declare_parameter("exploration.frontier_nearby_object_radius", 3.0)
        self.declare_parameter("exploration.frontier_grounding_angle_threshold", 0.7854)
        self.declare_parameter("exploration.frontier_cooccurrence_bonus", 0.25)
        self.declare_parameter("exploration.frontier_grounding_spatial_bonus", 0.1)
        self.declare_parameter("exploration.frontier_grounding_keyword_bonus", 0.4)
        self.declare_parameter("exploration.frontier_grounding_relation_bonus", 0.15)
        # åˆ›æ–°3: Frontier è§†è§‰è¯„åˆ†æƒé‡ (VLFM æ ¸å¿ƒ)
        self.declare_parameter("exploration.frontier_vision_weight", 0.0)

        # SG-Nav å¯¹é½å‚æ•°
        self.declare_parameter("exploration.sgnav.max_subgraphs", 6)
        self.declare_parameter("exploration.sgnav.use_llm_reasoning", True)
        self.declare_parameter("exploration.sgnav.heuristic_weight", 0.45)
        self.declare_parameter("exploration.sgnav.llm_weight", 0.55)
        self.declare_parameter("exploration.sgnav.frontier_base_weight", 0.55)
        self.declare_parameter("exploration.sgnav.room_gate_weight", 0.25)
        self.declare_parameter("exploration.sgnav.interp_decay_distance", 4.0)
        self.declare_parameter("exploration.sgnav.credibility_decay", 0.9)
        self.declare_parameter("exploration.sgnav.false_positive_penalty", 0.2)
        self.declare_parameter("exploration.sgnav.reject_threshold", 0.25)
        self.declare_parameter("exploration.sgnav.min_confidence_for_bypass", 0.85)
        self.declare_parameter("exploration.sgnav.arrival_reperception", True)
        # åˆ›æ–°3: è¿ç»­ Re-perception (å¯¼èˆªä¸­æ¯ N ç±³è§¦å‘)
        self.declare_parameter("exploration.sgnav.continuous_reperception", True)
        self.declare_parameter("exploration.sgnav.reperception_interval_m", 2.0)

        # LOVON é£æ ¼éšå¼ FSM: s_{t+1} = f_theta(obs_t, s_t, instruction)
        self.declare_parameter("fsm.mode", "implicit")            # explicit | implicit
        self.declare_parameter("fsm.implicit.weights_path", "")
        self.declare_parameter("fsm.implicit.strict", False)

        # B5: Nav2 NavigateToPose action å‚æ•°
        self.declare_parameter("nav2.use_action_client", True)
        self.declare_parameter("nav2.action_name", "navigate_to_pose")
        self.declare_parameter("nav2.action_timeout_sec", 120.0)

        # å®‰å…¨çº¦æŸ
        self.declare_parameter("safety.max_goal_distance", 50.0)

        # Vision grounding
        self.declare_parameter("vision.enable", True)
        self.declare_parameter("vision.image_topic", "/camera/color/image_raw")
        self.declare_parameter("vision.verify_threshold", 0.5)

        # æ‰§è¡Œå‚æ•° (C8, C9 å‚æ•°åŒ–)
        self.declare_parameter("execution.arrival_radius", 1.0)
        self.declare_parameter("execution.monitor_hz", 1.0)
        self.declare_parameter("execution.look_around_hz", 10.0)
        self.declare_parameter("execution.default_timeout", 300.0)

        # æ‹“æ‰‘è®°å¿† (C7 å‚æ•°åŒ–)
        self.declare_parameter("topo_memory.new_node_distance", 2.0)
        self.declare_parameter("topo_memory.max_nodes", 500)

        # â”€â”€ è¯»å–å‚æ•° â”€â”€
        primary_config = LLMConfig(
            backend=self.get_parameter("llm.backend").value,
            model=self.get_parameter("llm.model").value,
            api_key_env=self.get_parameter("llm.api_key_env").value,
            timeout_sec=self.get_parameter("llm.timeout_sec").value,
            max_retries=self.get_parameter("llm.max_retries").value,
            temperature=self.get_parameter("llm.temperature").value,
        )

        fallback_config = LLMConfig(
            backend=self.get_parameter("llm_fallback.backend").value,
            model=self.get_parameter("llm_fallback.model").value,
            api_key_env=self.get_parameter("llm_fallback.api_key_env").value,
            timeout_sec=self.get_parameter("llm_fallback.timeout_sec").value,
            max_retries=self.get_parameter("llm_fallback.max_retries").value,
        )

        self._confidence_threshold = self.get_parameter(
            "goal_resolution.confidence_threshold"
        ).value
        self._replan_on_failure = self.get_parameter(
            "goal_resolution.replan_on_failure"
        ).value
        self._max_replan_attempts = self.get_parameter(
            "goal_resolution.max_replan_attempts"
        ).value
        self._explore_enabled = self.get_parameter("exploration.enable").value
        self._exploration_strategy = self.get_parameter("exploration.strategy").value
        self._max_explore_steps = self.get_parameter("exploration.max_explore_steps").value
        self._step_distance = self.get_parameter("exploration.step_distance").value
        self._frontier_score_threshold = self.get_parameter(
            "exploration.frontier_score_threshold"
        ).value
        self._sgnav_use_llm_reasoning = self.get_parameter(
            "exploration.sgnav.use_llm_reasoning"
        ).value
        self._fsm_mode = self.get_parameter("fsm.mode").value
        self._max_goal_distance = self.get_parameter("safety.max_goal_distance").value
        self._arrival_radius = self.get_parameter("execution.arrival_radius").value
        self._monitor_hz = self.get_parameter("execution.monitor_hz").value
        self._vision_verify_threshold = self.get_parameter("vision.verify_threshold").value

        # â”€â”€ ç›®æ ‡è§£æå™¨ â”€â”€
        self._resolver = GoalResolver(
            primary_config=primary_config,
            fallback_config=fallback_config,
            confidence_threshold=self._confidence_threshold,
            fast_path_threshold=self.get_parameter(
                "goal_resolution.fast_path_threshold"
            ).value,
            max_replan_attempts=self._max_replan_attempts,
        )

        # â”€â”€ å­æ¨¡å— â”€â”€
        # KG æ³¨å…¥åˆ° TaskDecomposer (å®‰å…¨é—¨ + å¯ä¾›æ€§éªŒè¯)
        try:
            from semantic_perception.knowledge_graph import IndustrialKnowledgeGraph
            _kg = IndustrialKnowledgeGraph()
            TaskDecomposer.set_knowledge_graph(_kg)
            self.get_logger().info("KG injected into TaskDecomposer (%d concepts)", len(_kg.get_all_concepts()))
        except Exception as e:
            self.get_logger().warning("KG injection into TaskDecomposer failed (non-critical): %s", e)
        self._decomposer = TaskDecomposer()
        self._topo_memory = TopologicalMemory(
            new_node_distance=self.get_parameter("topo_memory.new_node_distance").value,
            max_nodes=self.get_parameter("topo_memory.max_nodes").value,
        )
        self._frontier_scorer = FrontierScorer(
            min_frontier_size=self.get_parameter("exploration.frontier_min_size").value,
            max_frontiers=self.get_parameter("exploration.frontier_max_count").value,
            cluster_radius_cells=self.get_parameter(
                "exploration.frontier_cluster_radius_cells"
            ).value,
            distance_weight=self.get_parameter("exploration.frontier_distance_weight").value,
            novelty_weight=self.get_parameter("exploration.frontier_novelty_weight").value,
            language_weight=self.get_parameter("exploration.frontier_language_weight").value,
            grounding_weight=self.get_parameter("exploration.frontier_grounding_weight").value,
            novelty_distance=self.get_parameter("exploration.frontier_novelty_distance").value,
            nearby_object_radius=self.get_parameter("exploration.frontier_nearby_object_radius").value,
            grounding_angle_threshold=self.get_parameter("exploration.frontier_grounding_angle_threshold").value,
            cooccurrence_bonus=self.get_parameter("exploration.frontier_cooccurrence_bonus").value,
            grounding_spatial_bonus=self.get_parameter("exploration.frontier_grounding_spatial_bonus").value,
            grounding_keyword_bonus=self.get_parameter("exploration.frontier_grounding_keyword_bonus").value,
            grounding_relation_bonus=self.get_parameter("exploration.frontier_grounding_relation_bonus").value,
            vision_weight=self.get_parameter("exploration.frontier_vision_weight").value,
        )
        self._sgnav_reasoner = SGNavReasoner(
            max_subgraphs=self.get_parameter("exploration.sgnav.max_subgraphs").value,
            use_llm_reasoning=self._sgnav_use_llm_reasoning,
            heuristic_weight=self.get_parameter("exploration.sgnav.heuristic_weight").value,
            llm_weight=self.get_parameter("exploration.sgnav.llm_weight").value,
            frontier_base_weight=self.get_parameter(
                "exploration.sgnav.frontier_base_weight"
            ).value,
            room_gate_weight=self.get_parameter(
                "exploration.sgnav.room_gate_weight"
            ).value,
            interp_decay_distance=self.get_parameter(
                "exploration.sgnav.interp_decay_distance"
            ).value,
            credibility_decay=self.get_parameter(
                "exploration.sgnav.credibility_decay"
            ).value,
            false_positive_penalty=self.get_parameter(
                "exploration.sgnav.false_positive_penalty"
            ).value,
            reject_threshold=self.get_parameter(
                "exploration.sgnav.reject_threshold"
            ).value,
            min_confidence_for_bypass=self.get_parameter(
                "exploration.sgnav.min_confidence_for_bypass"
            ).value,
        )
        self._implicit_fsm = ImplicitFSMPolicy(
            weights_path=self.get_parameter("fsm.implicit.weights_path").value,
            strict=self.get_parameter("fsm.implicit.strict").value,
        )
        self._action_executor = ActionExecutor()

        # BA-HSG: VoI ä¿¡æ¯ä»·å€¼è°ƒåº¦å™¨ (æ›¿ä»£å›ºå®š 2m è§¦å‘)
        self._voi_scheduler = VoIScheduler(VoIConfig())
        self._voi_enabled = True
        self._last_voi_reperception_time: float = 0.0
        self._last_voi_slow_time: float = 0.0

        # è·Ÿéšæ¨¡å¼æ ‡è®° (FOLLOW åŠ¨ä½œé€šè¿‡ç°æœ‰å¯¼èˆªé—­ç¯å®ç°)
        self._follow_mode: bool = False
        self._follow_target_label: str = ""
        self._follow_timeout: float = 300.0
        self._follow_start_time: float = 0.0

        # B5: Nav2 NavigateToPose action client
        self._use_nav2_action = self.get_parameter("nav2.use_action_client").value
        self._nav2_action_timeout = self.get_parameter("nav2.action_timeout_sec").value
        self._nav2_action_client: Optional[ActionClient] = None
        self._nav2_goal_handle: Optional[ClientGoalHandle] = None
        self._nav2_goal_active = False

        if self._use_nav2_action and _HAS_NAV2:
            action_name = self.get_parameter("nav2.action_name").value
            self._nav2_action_client = ActionClient(
                self, NavigateToPose, action_name
            )
            self.get_logger().info(f"Nav2 action client created: {action_name}")
        elif self._use_nav2_action and not _HAS_NAV2:
            self.get_logger().warn(
                "nav2_msgs not available, falling back to PoseStamped publishing"
            )
            self._use_nav2_action = False

        # â”€â”€ å†…éƒ¨çŠ¶æ€ â”€â”€
        self._state = PlannerState.IDLE
        self._current_instruction: Optional[str] = None
        self._current_language: str = "zh"
        self._current_explore_if_unknown: bool = True
        self._instruction_timeout: float = self.get_parameter(
            "execution.default_timeout"
        ).value
        self._latest_scene_graph: str = "{}"
        self._robot_position: Optional[Dict[str, float]] = None
        self._current_goal: Optional[GoalResult] = None
        self._current_plan: Optional[TaskPlan] = None
        self._current_action_cmd: Optional[ActionCommand] = None
        self._replan_count: int = 0
        self._explore_count: int = 0
        self._task_start_time: float = 0.0
        self._execution_context: str = ""  # GAP: é—­ç¯åé¦ˆ â€” æˆåŠŸæ—¶ç´¯è®¡åœºæ™¯å˜åŒ–

        # åˆ›æ–°3: è¿ç»­ Re-perception çŠ¶æ€
        self._continuous_reperception = self.get_parameter(
            "exploration.sgnav.continuous_reperception"
        ).value
        self._reperception_interval_m = self.get_parameter(
            "exploration.sgnav.reperception_interval_m"
        ).value
        self._last_reperception_dist: float = 0.0  # ä¸Šæ¬¡è§¦å‘æ—¶çš„ç´¯è®¡è·ç¦»
        self._nav_accumulated_dist: float = 0.0    # æœ¬æ¬¡å¯¼èˆªç´¯è®¡è·ç¦»
        self._last_fb_position: Optional[Dict[str, float]] = None  # ä¸Šæ¬¡ feedback ä½ç½®

        # éšå¼ FSM å†…éƒ¨çŠ¶æ€ (LOVON é£æ ¼ 4-state)
        self._fsm_prev_instruction: str = ""
        self._fsm_mission_state: str = "searching_1"
        self._fsm_search_state: str = "had_searching_1"

        # Vision: æœ€è¿‘çš„ç›¸æœºå¸§ (ç”¨äº VLM grounding)
        self._latest_image_base64: Optional[str] = None
        self._vision_enabled = self.get_parameter("vision.enable").value

        # å¼‚æ­¥äº‹ä»¶å¾ªç¯ (åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œ LLM è°ƒç”¨)
        self._loop = asyncio.new_event_loop()
        self._async_thread = threading.Thread(
            target=self._run_async_loop, daemon=True
        )
        self._async_thread.start()

        # â”€â”€ è®¢é˜… â”€â”€
        self._sub_instruction = self.create_subscription(
            String, "instruction", self._instruction_callback, 10
        )
        self._sub_scene_graph = self.create_subscription(
            String, "scene_graph", self._scene_graph_callback, 10
        )
        self._sub_odom = self.create_subscription(
            Odometry, "odometry", self._odom_callback, 10
        )

        self._sub_costmap = None
        if self._exploration_strategy in ("frontier", "sg_nav"):
            costmap_topic = self.get_parameter("exploration.costmap_topic").value
            self._sub_costmap = self.create_subscription(
                OccupancyGrid, costmap_topic, self._costmap_callback, 1
            )
            self.get_logger().info(f"Frontier exploration enabled, costmap={costmap_topic}")

        # F1: ä»»åŠ¡å–æ¶ˆè¯é¢˜
        self._sub_cancel = self.create_subscription(
            String, "/nav/semantic/cancel", self._cancel_callback, 10
        )

        # å¯é€‰: è®¢é˜…ç›¸æœºå›¾åƒ (ç”¨äº VLM vision grounding)
        if self._vision_enabled:
            image_topic = self.get_parameter("vision.image_topic").value
            self._sub_image = self.create_subscription(
                Image, image_topic, self._image_callback, 1
            )

        # â”€â”€ å‘å¸ƒ â”€â”€
        self._pub_goal = self.create_publisher(PoseStamped, "resolved_goal", 10)
        # A8 ä¿®å¤: ä½¿ç”¨ç›¸å¯¹è¯é¢˜å, ç”± launch æ–‡ä»¶ remap
        self._pub_cmd_vel = self.create_publisher(Twist, "cmd_vel", 10)
        self._pub_status = self.create_publisher(String, "status", 10)
        self._look_around_timer = None

        # â”€â”€ ç›‘æ§å®šæ—¶å™¨ (C9: å‚æ•°åŒ–é¢‘ç‡) â”€â”€
        monitor_period = 1.0 / max(self._monitor_hz, 0.1)
        self._monitor_timer = self.create_timer(monitor_period, self._monitor_callback)

        self.get_logger().info(
            f"SemanticPlannerNode started: "
            f"primary_llm={primary_config.backend}/{primary_config.model}, "
            f"fallback={fallback_config.backend}/{fallback_config.model}, "
            f"exploration_strategy={self._exploration_strategy}, "
            f"fsm_mode={self._fsm_mode}, "
            f"implicit_fsm_ready={self._implicit_fsm.is_ready}"
        )

    # ================================================================
    #  å¼‚æ­¥äº‹ä»¶å¾ªç¯
    # ================================================================

    def _run_async_loop(self):
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥äº‹ä»¶å¾ªç¯ã€‚"""
        asyncio.set_event_loop(self._loop)
        self._loop.run_forever()

    def _schedule_async(self, coro):
        """åœ¨å¼‚æ­¥çº¿ç¨‹ä¸­è°ƒåº¦åç¨‹ã€‚"""
        asyncio.run_coroutine_threadsafe(coro, self._loop)

    # ================================================================
    #  Callbacks
    # ================================================================

    def _instruction_callback(self, msg: String):
        """
        æ¥æ”¶æ–°çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚

        æµç¨‹ (SayCan + SG-Nav):
          1. è§£ææŒ‡ä»¤å‚æ•°
          2. å°è¯•è§„åˆ™åˆ†è§£ (ç®€å•æŒ‡ä»¤ä¸éœ€è¦ LLM)
          3. è§„åˆ™åˆ†è§£å¤±è´¥ â†’ LLM åˆ†è§£
          4. å¼€å§‹æ‰§è¡Œç¬¬ä¸€ä¸ªå­ç›®æ ‡
        """
        try:
            data = json.loads(msg.data)
            instruction = data.get("instruction", "")
            language = data.get("language", "zh") or "zh"
            explore = data.get("explore_if_unknown", True)
            timeout = data.get("timeout_sec", self._instruction_timeout)
            radius = data.get("arrival_radius", self._arrival_radius)
        except (json.JSONDecodeError, AttributeError):
            instruction = msg.data
            language = "zh"
            explore = True
            timeout = self._instruction_timeout
            radius = self._arrival_radius

        if not instruction:
            self.get_logger().warn("Empty instruction received, ignoring")
            return

        self.get_logger().info(
            f"New semantic instruction: '{instruction}' "
            f"(lang={language}, explore={explore})"
        )

        # é‡ç½®çŠ¶æ€
        self._fsm_prev_instruction = self._current_instruction or instruction
        self._current_instruction = instruction
        self._current_language = language
        self._current_explore_if_unknown = explore
        self._instruction_timeout = timeout
        self._arrival_radius = radius
        self._replan_count = 0
        self._explore_count = 0
        self._execution_context = ""
        self._task_start_time = time.time()
        self._resolver.reset_exploration()
        self._sgnav_reasoner.reset()
        self._fsm_mission_state = "searching_1"
        self._fsm_search_state = "had_searching_1"
        self._action_executor.reset()
        self._current_plan = None

        # Step 1: ä»»åŠ¡åˆ†è§£ (SayCan)
        plan = self._decomposer.decompose_with_rules(instruction)
        if plan:
            self.get_logger().info(
                f"Rule-based decomposition: {len(plan.subgoals)} subgoals"
            )
            self._current_plan = plan
            self._execute_next_subgoal()
        else:
            self.get_logger().info("Complex instruction, using LLM decomposition")
            self._set_state(PlannerState.DECOMPOSING)
            self._schedule_async(self._llm_decompose())

    def _cancel_callback(self, msg: String):
        """
        F1: ä»»åŠ¡å–æ¶ˆã€‚

        æ¥æ”¶ /nav/semantic/cancel æ¶ˆæ¯, åœæ­¢å½“å‰ä»»åŠ¡ã€‚
        """
        reason = msg.data if msg.data else "User requested cancel"
        self.get_logger().info(f"Task cancelled: {reason}")

        # B5: å–æ¶ˆ Nav2 action goal
        if self._nav2_goal_handle is not None and self._nav2_goal_active:
            try:
                self._nav2_goal_handle.cancel_goal_async()
                self.get_logger().info("Nav2 goal cancel requested")
            except Exception as e:
                self.get_logger().debug(f"Nav2 cancel failed: {e}")
            self._nav2_goal_active = False

        # åœæ­¢è¿åŠ¨
        stop = Twist()
        self._pub_cmd_vel.publish(stop)

        # åœæ­¢æ—‹è½¬å®šæ—¶å™¨
        if self._look_around_timer is not None:
            self._look_around_timer.cancel()
            self._look_around_timer = None

        # é‡ç½®çŠ¶æ€
        self._action_executor.reset()
        self._set_state(PlannerState.CANCELLED)

    def _scene_graph_callback(self, msg: String):
        """æ›´æ–°æœ€æ–°åœºæ™¯å›¾ã€‚"""
        self._latest_scene_graph = msg.data

    def _image_callback(self, msg: Image):
        """ç¼“å­˜æœ€æ–°ç›¸æœºå¸§ (ç”¨äº VLM vision grounding)ã€‚"""
        try:
            import cv2
            import base64
            from cv_bridge import CvBridge

            bridge = CvBridge()
            bgr = bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")

            # å‹ç¼©ä¸º JPEG base64 (é™ä½åˆ†è¾¨ç‡ä»¥èŠ‚çœ API è´¹ç”¨)
            h, w = bgr.shape[:2]
            if w > 512:
                scale = 512 / w
                bgr = cv2.resize(bgr, (512, int(h * scale)))

            _, buf = cv2.imencode(".jpg", bgr, [cv2.IMWRITE_JPEG_QUALITY, 60])
            self._latest_image_base64 = base64.b64encode(buf).decode("utf-8")
        except Exception as e:
            # A3 ä¿®å¤: ä¸å† `pass`, è®°å½•æ—¥å¿—
            self.get_logger().debug(f"Image encoding failed (non-critical): {e}")

    def _odom_callback(self, msg: Odometry):
        """æ›´æ–°æœºå™¨äººä½ç½®ã€‚"""
        p = msg.pose.pose.position
        self._robot_position = {
            "x": p.x, "y": p.y, "z": p.z,
        }

    def _costmap_callback(self, msg: OccupancyGrid):
        """ç¼“å­˜å æ®æ …æ ¼, ä¾› Frontier è¯„åˆ†æ¢ç´¢ä½¿ç”¨ã€‚"""
        try:
            width = int(msg.info.width)
            height = int(msg.info.height)
            if width <= 0 or height <= 0:
                return

            expected = width * height
            if len(msg.data) != expected:
                self.get_logger().warn(
                    f"Invalid costmap data length: {len(msg.data)} != {expected}"
                )
                return

            grid = np.asarray(msg.data, dtype=np.int16).reshape((height, width))
            self._frontier_scorer.update_costmap(
                grid_data=grid,
                resolution=float(msg.info.resolution),
                origin_x=float(msg.info.origin.position.x),
                origin_y=float(msg.info.origin.position.y),
            )
        except Exception as e:
            self.get_logger().warn(f"Costmap parse failed: {e}")

    # ================================================================
    #  ä»»åŠ¡åˆ†è§£ (SayCan, å¼‚æ­¥)
    # ================================================================

    async def _llm_decompose(self):
        """LLM åˆ†è§£å¤æ‚æŒ‡ä»¤ (SayCan / Inner Monologue)ã€‚"""
        try:
            # è·å–åœºæ™¯æ‘˜è¦
            scene_summary = ""
            try:
                sg = json.loads(self._latest_scene_graph)
                scene_summary = sg.get("summary", "")
            except (json.JSONDecodeError, TypeError) as e:
                # A3 ä¿®å¤: è®°å½•æ—¥å¿—
                self.get_logger().debug(f"Scene graph parse failed: {e}")
            if self._execution_context:
                scene_summary = (scene_summary or "") + "\n\n[Execution history]\n" + self._execution_context

            messages = self._decomposer.build_decomposition_prompt(
                self._current_instruction, scene_summary, self._current_language
            )
            response = await self._resolver._call_with_fallback(messages)

            if response:
                plan = self._decomposer.parse_decomposition_response(
                    self._current_instruction, response
                )
            else:
                # LLM å¤±è´¥, fallback: ç®€å• NAVIGATE + VERIFY
                plan = TaskPlan(
                    instruction=self._current_instruction,
                    subgoals=[
                        SubGoal(step_id=0, action=SubGoalAction.NAVIGATE,
                                target=self._current_instruction),
                        SubGoal(step_id=1, action=SubGoalAction.VERIFY,
                                target=self._current_instruction),
                    ],
                )

            self.get_logger().info(
                f"LLM decomposition: {len(plan.subgoals)} subgoals: "
                + " â†’ ".join(f"{sg.action.value}({sg.target})" for sg in plan.subgoals)
            )
            self._current_plan = plan
            self._execute_next_subgoal()

        except Exception as e:
            self.get_logger().error(
                f"Decomposition failed: {e}\n{traceback.format_exc()}"
            )
            self._set_state(PlannerState.FAILED)

    # ================================================================
    #  å­ç›®æ ‡æ‰§è¡Œå¼•æ“ (LOVON åŠ¨ä½œåŸè¯­)
    # ================================================================

    def _execute_next_subgoal(self):
        """æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªå­ç›®æ ‡å¹¶æ‰§è¡Œã€‚"""
        # F1: æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
        if self._state == PlannerState.CANCELLED:
            return

        if self._current_plan is None:
            self._set_state(PlannerState.FAILED)
            return

        if self._current_plan.is_complete:
            self.get_logger().info("All subgoals completed!")
            self._set_state(PlannerState.COMPLETED)
            return

        if self._current_plan.is_failed:
            self.get_logger().error("Task plan failed (subgoal exhausted retries)")
            self._set_state(PlannerState.FAILED)
            return

        subgoal = self._current_plan.active_subgoal
        if subgoal is None:
            self._set_state(PlannerState.COMPLETED)
            return

        subgoal.status = SubGoalStatus.ACTIVE
        self.get_logger().info(
            f"Executing subgoal [{subgoal.step_id}]: "
            f"{subgoal.action.value}({subgoal.target})"
        )

        # æ ¹æ®åŠ¨ä½œç±»å‹åˆ†å‘
        if subgoal.action == SubGoalAction.NAVIGATE:
            self._set_state(PlannerState.RESOLVING)
            self._schedule_async(self._resolve_goal())

        elif subgoal.action == SubGoalAction.FIND:
            self._set_state(PlannerState.RESOLVING)
            self._schedule_async(self._resolve_goal())

        elif subgoal.action == SubGoalAction.APPROACH:
            self._execute_approach(subgoal)

        elif subgoal.action == SubGoalAction.VERIFY:
            self._execute_verify(subgoal)

        elif subgoal.action == SubGoalAction.LOOK_AROUND:
            self._execute_look_around(subgoal)

        elif subgoal.action == SubGoalAction.EXPLORE:
            self._set_state(PlannerState.EXPLORING)
            self._schedule_async(self._resolve_goal())

        elif subgoal.action == SubGoalAction.BACKTRACK:
            self._execute_backtrack(subgoal)

        elif subgoal.action == SubGoalAction.STOP:
            self.get_logger().info("â¹ STOP action â€” cancelling current task")
            self._cancel_navigation()
            self._set_state(PlannerState.IDLE)
            self._advance_subgoal()

        elif subgoal.action == SubGoalAction.PICK:
            self.get_logger().info(
                "ğŸ¤ PICK action: target='%s' â€” resolving position then approaching",
                subgoal.target,
            )
            self._set_state(PlannerState.RESOLVING)
            self._schedule_async(self._resolve_goal())

        elif subgoal.action == SubGoalAction.PLACE:
            self.get_logger().info(
                "ğŸ“¦ PLACE action: target='%s' â€” navigating to drop location",
                subgoal.target,
            )
            self._set_state(PlannerState.RESOLVING)
            self._schedule_async(self._resolve_goal())

        elif subgoal.action == SubGoalAction.STATUS:
            self.get_logger().info("ğŸ“Š STATUS query â€” reporting system state")
            self._publish_status_report(subgoal.target or "all")
            self._advance_subgoal()

        elif subgoal.action == SubGoalAction.FOLLOW:
            # FOLLOW å¤ç”¨å®Œæ•´å¯¼èˆªé—­ç¯: resolve â†’ navigate â†’ åˆ°è¾¾ â†’ re-resolve â†’ navigate ...
            # å’Œ NAVIGATE èµ°åŒä¸€æ¡è·¯, åŒºåˆ«ä»…åœ¨äº _follow_mode æ ‡è®°
            self._follow_mode = True
            self._follow_target_label = subgoal.target or "person"
            self._follow_timeout = (
                subgoal.parameters.get("timeout", 300.0) if subgoal.parameters else 300.0
            )
            self._follow_start_time = time.time()
            self.get_logger().info(
                "ğŸƒ Follow mode: target='%s', timeout=%.0fs â€” "
                "using existing VLN loop (perceiveâ†’resolveâ†’navigateâ†’re-perceive)",
                self._follow_target_label, self._follow_timeout,
            )
            self._set_state(PlannerState.RESOLVING)
            self._schedule_async(self._resolve_goal())

        elif subgoal.action == SubGoalAction.WAIT:
            wait_sec = subgoal.parameters.get("wait_sec", 3.0)
            self.get_logger().info(f"Waiting {wait_sec}s...")
            self.create_timer(
                wait_sec,
                lambda: self._subgoal_completed(),
            )

    def _execute_approach(self, subgoal: SubGoal):
        """æ‰§è¡Œ APPROACH å­ç›®æ ‡ (LOVON)ã€‚"""
        if not self._robot_position or not self._current_goal:
            self._subgoal_failed("No position or goal for APPROACH")
            return

        target_pos = {
            "x": self._current_goal.target_x,
            "y": self._current_goal.target_y,
            "z": self._current_goal.target_z,
        }

        cmd = self._action_executor.generate_approach_command(
            target_pos, self._robot_position
        )
        self._publish_goal_from_command(cmd)
        self._set_state(PlannerState.APPROACHING)

    def _execute_verify(self, subgoal: SubGoal):
        """
        æ‰§è¡Œ VERIFY å­ç›®æ ‡ (LOVON + VLMnav)ã€‚

        A4 ä¿®å¤: å¼‚å¸¸æ—¶ä¸å†é»˜è®¤ success, è€Œæ˜¯æ ‡è®° FAILED è§¦å‘é‡è¯•ã€‚
        """
        self._set_state(PlannerState.VERIFYING)

        if self._vision_enabled and self._latest_image_base64:
            self._schedule_async(self._vision_verify(subgoal))
        else:
            # æ—  VLM, åŸºäºç½®ä¿¡åº¦åˆ¤æ–­
            if (self._current_goal
                    and self._current_goal.confidence > self._confidence_threshold):
                self.get_logger().info("VERIFY passed (confidence-based, no VLM)")
                self._subgoal_completed()
            else:
                self.get_logger().warn(
                    "VERIFY uncertain (no VLM, low confidence) â€” passing with warning"
                )
                # ä½ç½®ä¿¡åº¦ + æ—  VLM: ä»ç„¶é€šè¿‡ä½†è®°å½• warning
                self._subgoal_completed()

    async def _vision_verify(self, subgoal: SubGoal):
        """VLM è§†è§‰éªŒè¯ (VLMnav æ–¹æ¡ˆ)ã€‚"""
        try:
            result = await self._resolver.vision_grounding(
                instruction=subgoal.target,
                scene_graph_json=self._latest_scene_graph,
                image_base64=self._latest_image_base64,
                language=self._current_language,
            )

            visible = result.get("target_visible", False)
            confidence = result.get("confidence", 0.0)
            reasoning = result.get("reasoning", "")

            self.get_logger().info(
                f"VERIFY result: visible={visible}, "
                f"confidence={confidence:.2f}, reason={reasoning}"
            )

            if visible and confidence > self._vision_verify_threshold:
                self._subgoal_completed()
            else:
                self.get_logger().warn(
                    f"VERIFY failed: target not confirmed ({reasoning})"
                )
                self._subgoal_failed(f"VLM verification failed: {reasoning}")

        except Exception as e:
            # A4 ä¿®å¤: å¼‚å¸¸æ—¶ä¸å†é»˜è®¤ success
            self.get_logger().error(
                f"Vision verify error: {e}\n{traceback.format_exc()}"
            )
            self._subgoal_failed(f"VLM verify exception: {e}")

    def _publish_status_report(self, query: str):
        """Publish robot status (battery, pose, task, mode) to feedback topic."""
        report = {
            "query": query,
            "state": self._state.value if self._state else "unknown",
            "active_task": str(self._current_plan.instruction) if self._current_plan else None,
            "follow_mode": getattr(self, "_follow_mode", False),
        }
        self.get_logger().info("Status report: %s", report)

    def _execute_look_around(self, subgoal: SubGoal):
        """æ‰§è¡Œ LOOK_AROUND (LOVON: åŸåœ° 360Â° æ‰«æ)ã€‚"""
        cmd = self._action_executor.generate_look_around_command()
        self._current_action_cmd = cmd
        self._set_state(PlannerState.LOOKING_AROUND)

        # æŒç»­å‘å¸ƒæ—‹è½¬é€Ÿåº¦ (C9 å‚æ•°åŒ–)
        look_hz = self.get_parameter("execution.look_around_hz").value
        self._look_around_timer = self.create_timer(
            1.0 / max(look_hz, 1.0), self._publish_look_around_twist
        )

        # æ—‹è½¬å®Œæˆååœæ­¢å¹¶æ¨è¿›å­ç›®æ ‡
        self.create_timer(
            cmd.timeout_sec,
            lambda: self._finish_look_around(),
        )

    def _publish_look_around_twist(self):
        """å‘å¸ƒ LOOK_AROUND æ—‹è½¬ Twistã€‚"""
        if self._state != PlannerState.LOOKING_AROUND:
            return
        twist = Twist()
        twist.angular.z = (
            self._current_action_cmd.angular_z if self._current_action_cmd else 0.0
        )
        self._pub_cmd_vel.publish(twist)

    def _finish_look_around(self):
        """åœæ­¢æ—‹è½¬, å®Œæˆ LOOK_AROUND å­ç›®æ ‡ã€‚"""
        stop = Twist()
        self._pub_cmd_vel.publish(stop)

        if self._look_around_timer is not None:
            self._look_around_timer.cancel()
            self._look_around_timer = None

        self._subgoal_completed()

    def _execute_backtrack(self, subgoal: SubGoal):
        """æ‰§è¡Œ BACKTRACK (LOVON: å›æº¯åˆ°ä¸Šä¸€ä½ç½®)ã€‚"""
        backtrack_pos = self._topo_memory.get_backtrack_position(steps_back=2)
        if backtrack_pos is not None:
            cmd = self._action_executor.generate_backtrack_command(backtrack_pos)
            self._publish_goal_from_command(cmd)
            self._set_state(PlannerState.BACKTRACKING)
        else:
            self.get_logger().warn("BACKTRACK: no history, skipping")
            self._subgoal_completed()

    def _subgoal_completed(self):
        """å½“å‰å­ç›®æ ‡å®Œæˆ, æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªã€‚GAP: é—­ç¯åé¦ˆ â€” æˆåŠŸæ—¶ç´¯ç§¯æ‰§è¡Œä¸Šä¸‹æ–‡ã€‚"""
        if self._current_plan:
            active = self._current_plan.active_subgoal

            # â”€â”€ è·Ÿéšæ¨¡å¼: åˆ°è¾¾ â‰  ç»“æŸ, é‡æ–°è§£æç›®æ ‡ç»§ç»­å¯¼èˆª â”€â”€
            if (self._follow_mode and active
                    and active.action in (SubGoalAction.NAVIGATE, SubGoalAction.FOLLOW)):
                elapsed = time.time() - self._follow_start_time
                if elapsed > self._follow_timeout:
                    self.get_logger().info(
                        "Follow mode timeout (%.0fs), completing.", elapsed,
                    )
                    self._follow_mode = False
                else:
                    self.get_logger().info(
                        "ğŸƒ Follow mode: arrived near target, re-resolving "
                        "(%.0fs / %.0fs)", elapsed, self._follow_timeout,
                    )
                    # ä¸ advance, ä¸ complete â€” é‡æ–°è§£æåŒä¸€ç›®æ ‡
                    self._set_state(PlannerState.RESOLVING)
                    self._schedule_async(self._resolve_goal())
                    return

            if active:
                self.get_logger().info(
                    f"Subgoal [{active.step_id}] {active.action.value} completed"
                )
            if self._current_goal and active:
                summary = self._build_success_summary(active)
                if summary:
                    self._execution_context = (
                        (self._execution_context + "\n" + summary)
                        if self._execution_context
                        else summary
                    )
                    self.get_logger().debug(f"Execution context: {summary[:80]}...")
            self._current_plan.advance()
            self._action_executor.reset()
            # é€€å‡ºè·Ÿéšæ¨¡å¼ (FOLLOW subgoal å·² advance)
            if self._follow_mode:
                self._follow_mode = False
        self._execute_next_subgoal()

    def _build_success_summary(self, subgoal) -> str:
        """GAP: æ„å»ºå­ç›®æ ‡æˆåŠŸæ—¶çš„å¯Œè¯­ä¹‰åé¦ˆ (Inner Monologue é£æ ¼)ã€‚"""
        target = getattr(subgoal, "target", "") or ""
        if not target:
            return ""
        try:
            sg = json.loads(self._latest_scene_graph)
            objs = sg.get("objects", [])
            if isinstance(objs, list) and objs:
                labels = [str(o.get("label", "")) for o in objs[:6] if o]
                visible = ", ".join(l for l in labels if l)
                if visible:
                    return f"Reached {target}. Visible: {visible}"
        except (json.JSONDecodeError, TypeError, KeyError):
            pass
        return f"Reached {target}."

    def _subgoal_failed(self, reason: str = ""):
        """å½“å‰å­ç›®æ ‡å¤±è´¥, å°è¯•é‡è¯•æˆ–æ”¾å¼ƒã€‚"""
        failed_subgoal: Optional[SubGoal] = None
        if self._current_plan:
            active = self._current_plan.active_subgoal

            # â”€â”€ è·Ÿéšæ¨¡å¼: å¤±è´¥ä¸æ”¾å¼ƒ, ç»§ç»­æœç´¢ â”€â”€
            if (self._follow_mode and active
                    and active.action in (SubGoalAction.NAVIGATE, SubGoalAction.FOLLOW)):
                elapsed = time.time() - self._follow_start_time
                if elapsed < self._follow_timeout:
                    self.get_logger().warn(
                        "ğŸƒ Follow mode: target lost (%s), "
                        "re-resolving (%.0fs / %.0fs)",
                        reason, elapsed, self._follow_timeout,
                    )
                    active.retry_count = 0  # è·Ÿéšæ¨¡å¼é‡ç½®é‡è¯•è®¡æ•°
                    self._set_state(PlannerState.RESOLVING)
                    self._schedule_async(self._resolve_goal())
                    return
                else:
                    self.get_logger().info(
                        "Follow mode timeout (%.0fs), stopping.", elapsed,
                    )
                    self._follow_mode = False

            if active:
                failed_subgoal = active
                self.get_logger().warn(
                    f"Subgoal [{active.step_id}] {active.action.value} failed: {reason}"
                )
            self._current_plan.fail_current()
            self._action_executor.reset()

            # é‡è¯•è€—å°½åè§¦å‘åé¦ˆé‡è§„åˆ’ (Inner Monologue é£æ ¼)
            exhausted = (
                failed_subgoal is not None
                and failed_subgoal.status == SubGoalStatus.FAILED
            )
            can_replan = (
                exhausted
                and self._replan_on_failure
                and self._replan_count < self._max_replan_attempts
            )
            if can_replan:
                self.get_logger().warn(
                    f"Subgoal retries exhausted, triggering replanning "
                    f"({self._replan_count + 1}/{self._max_replan_attempts})"
                )
                self._set_state(PlannerState.REPLANNING)
                self._schedule_async(self._llm_replan(reason, failed_subgoal))
                return

        self._execute_next_subgoal()

    async def _llm_replan(self, reason: str, failed_subgoal: Optional[SubGoal]):
        """åŸºäºæ‰§è¡Œåé¦ˆçš„ LLM é‡è§„åˆ’ã€‚"""
        try:
            self._replan_count += 1

            # åœºæ™¯æ‘˜è¦ + å¤±è´¥åé¦ˆ
            scene_summary = ""
            try:
                sg = json.loads(self._latest_scene_graph)
                scene_summary = sg.get("summary", "")
            except (json.JSONDecodeError, TypeError):
                scene_summary = ""

            failed_desc = "unknown"
            if failed_subgoal is not None:
                failed_desc = (
                    f"step={failed_subgoal.step_id}, "
                    f"action={failed_subgoal.action.value}, "
                    f"target={failed_subgoal.target}, "
                    f"retry={failed_subgoal.retry_count}/{failed_subgoal.max_retries}"
                )

            ctx = f"[Execution history]\n{self._execution_context}\n\n" if self._execution_context else ""
            feedback_summary = (
                f"{scene_summary}\n"
                f"{ctx}"
                f"[Execution Feedback]\n"
                f"Failed subgoal: {failed_desc}\n"
                f"Failure reason: {reason or 'unknown'}\n"
                "Please replan remaining subgoals from current scene and avoid repeating failed strategy."
            )

            messages = self._decomposer.build_decomposition_prompt(
                self._current_instruction or "",
                feedback_summary,
                self._current_language,
            )

            response = await self._resolver._call_with_fallback(messages)
            if not response:
                self.get_logger().error("Replan failed: no LLM response")
                self._set_state(PlannerState.FAILED)
                return

            new_plan = self._decomposer.parse_decomposition_response(
                self._current_instruction or "", response
            )
            if not new_plan.subgoals:
                self.get_logger().error("Replan failed: empty subgoal list")
                self._set_state(PlannerState.FAILED)
                return

            self.get_logger().info(
                f"Replan #{self._replan_count}: {len(new_plan.subgoals)} subgoals: "
                + " -> ".join(f"{sg.action.value}({sg.target})" for sg in new_plan.subgoals)
            )
            self._current_plan = new_plan
            self._execute_next_subgoal()

        except Exception as e:
            self.get_logger().error(
                f"LLM replan exception: {e}\n{traceback.format_exc()}"
            )
            self._set_state(PlannerState.FAILED)

    # ================================================================
    #  ç›®æ ‡è§£æ (VLingNav åŒè¿›ç¨‹ + ESCA é€‰æ‹©æ€§ Grounding)
    # ================================================================

    async def _resolve_goal(self):
        """
        å¼‚æ­¥è§£æç›®æ ‡ â€” Fast/Slow åŒè¿›ç¨‹ã€‚

        å‚è€ƒ:
          - VLingNav (2026): AdaCoT è‡ªé€‚åº”æ¨ç†
          - OmniNav (ICLR 2026): Fast-Slow ç³»ç»Ÿ
          - ESCA (NeurIPS 2025): é€‰æ‹©æ€§ Grounding
          - AdaNav (ICLR 2026): ä¸ç¡®å®šæ€§é©±åŠ¨æ¨ç†æ·±åº¦
        """
        try:
            result = await self._resolver.resolve(
                instruction=self._current_instruction,
                scene_graph_json=self._latest_scene_graph,
                robot_position=self._robot_position,
                language=self._current_language,
                explore_if_unknown=self._current_explore_if_unknown,
            )

            if not result.is_valid:
                self.get_logger().error(f"Goal resolution failed: {result.error}")
                self._subgoal_failed(result.error)
                return

            # LOVON é£æ ¼éšå¼ FSM: ç”¨å‚æ•°åŒ–æ¨¡å‹å†³å®šçŠ¶æ€è½¬ç§»
            if self._fsm_mode == "implicit":
                result = self._apply_implicit_fsm_transition(result)

            self._current_goal = result

            path_emoji = "âš¡" if result.path == "fast" else "ğŸ§ "
            self.get_logger().info(
                f"{path_emoji} Goal via {result.path} path: "
                f"'{result.target_label}' conf={result.confidence:.2f}"
            )

            # Slow è·¯å¾„ + ä½ç½®ä¿¡åº¦ + æœ‰ VLM â†’ é¢å¤–è§†è§‰éªŒè¯ (VLMnav)
            if (
                result.path == "slow"
                and result.confidence < self._confidence_threshold
                and self._vision_enabled
                and self._latest_image_base64
            ):
                self.get_logger().info(
                    "Low confidence on slow path, trying vision grounding..."
                )
                try:
                    vg_result = await self._resolver.vision_grounding(
                        instruction=self._current_instruction,
                        scene_graph_json=self._latest_scene_graph,
                        image_base64=self._latest_image_base64,
                        language=self._current_language,
                    )
                    if vg_result.get("target_visible", False):
                        result.confidence = max(
                            result.confidence, vg_result.get("confidence", 0.5)
                        )
                        self.get_logger().info(
                            f"Vision grounding: target visible, "
                            f"confidenceâ†’{result.confidence:.2f}"
                        )
                except Exception as e:
                    # A3 ä¿®å¤: è®°å½•æ—¥å¿—, ä¸é™é»˜å¤±è´¥
                    self.get_logger().warn(
                        f"Vision grounding failed (continuing): {e}"
                    )

            if result.action == "navigate":
                # SG-Nav: graph-based re-perception è¿‡æ»¤ä½å¯ä¿¡å‡é˜³æ€§ç›®æ ‡
                if self._exploration_strategy == "sg_nav":
                    accepted = await self._sgnav_reperception_check(result)
                    if not accepted:
                        self.get_logger().warn(
                            "SG-Nav re-perception rejected target, switching to exploration"
                        )
                        await self._handle_explore_result(
                            GoalResult(
                                action="explore",
                                confidence=max(0.05, result.confidence * 0.5),
                                reasoning="SG-Nav re-perception rejected low-credibility target",
                                is_valid=True,
                                path="sg_nav",
                            )
                        )
                        return

                self._handle_navigate_result(result)
            elif result.action == "explore":
                await self._handle_explore_result(result)
            else:
                self.get_logger().error(f"Unknown action: {result.action}")
                self._subgoal_failed(f"Unknown action: {result.action}")

        except Exception as e:
            self.get_logger().error(
                f"Goal resolution exception: {e}\n{traceback.format_exc()}"
            )
            self._subgoal_failed(str(e))

    def _handle_navigate_result(self, result: GoalResult):
        """å¤„ç†å¯¼èˆªç»“æœ â€” å‘å¸ƒç›®æ ‡ (B5: ä¼˜å…ˆç”¨ Nav2 action)ã€‚"""
        # å®‰å…¨æ£€æŸ¥: ç›®æ ‡è·ç¦»
        if self._robot_position:
            dist = math.sqrt(
                (result.target_x - self._robot_position["x"]) ** 2
                + (result.target_y - self._robot_position["y"]) ** 2
            )
            if dist > self._max_goal_distance:
                self.get_logger().warn(
                    f"Goal too far ({dist:.1f}m > {self._max_goal_distance}m), clamping"
                )
                scale = self._max_goal_distance / dist
                result.target_x = self._robot_position["x"] + (
                    result.target_x - self._robot_position["x"]
                ) * scale
                result.target_y = self._robot_position["y"] + (
                    result.target_y - self._robot_position["y"]
                ) * scale

        # æ„å»º PoseStamped
        goal_pose = PoseStamped()
        goal_pose.header.stamp = self.get_clock().now().to_msg()
        goal_pose.header.frame_id = result.frame_id  # ä½¿ç”¨ç›®æ ‡è§£æå™¨è¿”å›çš„åæ ‡ç³»
        goal_pose.pose.position.x = result.target_x
        goal_pose.pose.position.y = result.target_y
        goal_pose.pose.position.z = result.target_z

        if self._robot_position:
            dx = result.target_x - self._robot_position["x"]
            dy = result.target_y - self._robot_position["y"]
            yaw = math.atan2(dy, dx)
            goal_pose.pose.orientation.z = math.sin(yaw / 2)
            goal_pose.pose.orientation.w = math.cos(yaw / 2)
        else:
            goal_pose.pose.orientation.w = 1.0

        # B5: ä¼˜å…ˆä½¿ç”¨ Nav2 action client (æœ‰ feedback + å®Œæˆ/å¤±è´¥å›è°ƒ)
        if self._use_nav2_action and self._nav2_action_client is not None:
            self._send_nav2_goal(goal_pose, result.target_label or "")
        else:
            # å…œåº•: ç›´æ¥å‘å¸ƒ PoseStamped (æ—  feedback)
            self._pub_goal.publish(goal_pose)

        self._set_state(PlannerState.NAVIGATING)

        self.get_logger().info(
            f"Goal published: {result.target_label} "
            f"({result.target_x:.2f}, {result.target_y:.2f}, {result.target_z:.2f}) "
            f"confidence={result.confidence:.2f}"
            f"{' [Nav2 action]' if self._use_nav2_action else ' [PoseStamped]'}"
        )

    # ================================================================
    #  B5: Nav2 NavigateToPose action äº¤äº’
    # ================================================================

    def _send_nav2_goal(self, goal_pose: PoseStamped, target_label: str):
        """é€šè¿‡ Nav2 action å‘é€å¯¼èˆªç›®æ ‡, æ³¨å†Œ feedback/result å›è°ƒã€‚"""
        if not _HAS_NAV2 or self._nav2_action_client is None:
            self._pub_goal.publish(goal_pose)
            return

        # å–æ¶ˆå‰ä¸€ä¸ªè¿›è¡Œä¸­çš„ç›®æ ‡
        if self._nav2_goal_handle is not None and self._nav2_goal_active:
            self.get_logger().info("Cancelling previous Nav2 goal")
            try:
                self._nav2_goal_handle.cancel_goal_async()
            except Exception as e:
                self.get_logger().debug(f"Cancel previous goal failed: {e}")
            self._nav2_goal_active = False

        # ç­‰å¾… action server (éé˜»å¡, 1ç§’è¶…æ—¶)
        if not self._nav2_action_client.wait_for_server(timeout_sec=1.0):
            self.get_logger().warn("Nav2 action server not available, falling back to topic")
            self._pub_goal.publish(goal_pose)
            return

        goal_msg = NavigateToPose.Goal()
        goal_msg.pose = goal_pose

        # åˆ›æ–°3: é‡ç½®è¿ç»­ Re-perception çŠ¶æ€
        self._nav_accumulated_dist = 0.0
        self._last_reperception_dist = 0.0
        self._last_fb_position = None

        self.get_logger().info(f"Sending Nav2 goal: {target_label}")

        send_future = self._nav2_action_client.send_goal_async(
            goal_msg,
            feedback_callback=self._nav2_feedback_callback,
        )
        send_future.add_done_callback(self._nav2_goal_response_callback)

        # åŒæ—¶å‘å¸ƒåˆ° topic (å…¶ä»–èŠ‚ç‚¹å¯èƒ½ä¹Ÿåœ¨ç›‘å¬)
        self._pub_goal.publish(goal_pose)

    def _nav2_goal_response_callback(self, future):
        """Nav2 goal accepted/rejected å›è°ƒã€‚"""
        try:
            goal_handle = future.result()
        except Exception as e:
            self.get_logger().error(f"Nav2 goal send failed: {e}")
            self._nav2_goal_active = False
            return

        if not goal_handle.accepted:
            self.get_logger().warn("Nav2 goal was rejected")
            self._nav2_goal_active = False
            self._subgoal_failed("Nav2 goal rejected")
            return

        self.get_logger().info("Nav2 goal accepted")
        self._nav2_goal_handle = goal_handle
        self._nav2_goal_active = True

        # æ³¨å†Œç»“æœå›è°ƒ
        result_future = goal_handle.get_result_async()
        result_future.add_done_callback(self._nav2_result_callback)

    def _nav2_feedback_callback(self, feedback_msg):
        """
        Nav2 å¯¼èˆª feedback å›è°ƒ (B5 æ ¸å¿ƒ: å®æ—¶è¿›åº¦)ã€‚

        feedback åŒ…å«:
          - current_pose: å½“å‰ä½ç½®
          - navigation_time: å·²ç”¨æ—¶é—´
          - estimated_time_remaining: é¢„ä¼°å‰©ä½™æ—¶é—´
          - number_of_recoveries: æ¢å¤æ¬¡æ•°
          - distance_remaining: å‰©ä½™è·ç¦»
        
        åˆ›æ–°3 è¡¥å¼º: æ¯ç§»åŠ¨ reperception_interval_m (é»˜è®¤ 2m) è§¦å‘ä¸€æ¬¡
        åœºæ™¯å›¾åˆ·æ–° + credibility æ›´æ–°, å®ç°å¯¼èˆªä¸­çš„è¿ç»­ Re-perceptionã€‚
        """
        try:
            fb = feedback_msg.feedback
            dist_remaining = fb.distance_remaining
            nav_time = fb.navigation_time.sec + fb.navigation_time.nanosec * 1e-9
            n_recoveries = fb.number_of_recoveries

            # ä» feedback æå–å½“å‰ä½ç½®
            current_fb_pos = {
                "x": fb.current_pose.pose.position.x,
                "y": fb.current_pose.pose.position.y,
                "z": fb.current_pose.pose.position.z,
            }

            # ç´¯è®¡è¡Œé©¶è·ç¦»
            if self._last_fb_position is not None:
                dx = current_fb_pos["x"] - self._last_fb_position["x"]
                dy = current_fb_pos["y"] - self._last_fb_position["y"]
                self._nav_accumulated_dist += math.sqrt(dx * dx + dy * dy)
            self._last_fb_position = current_fb_pos

            # æ—¥å¿— (ä½é¢‘: ä»…å½“è·ç¦»å˜åŒ– > 0.5m æ—¶)
            if not hasattr(self, "_last_fb_dist") or abs(self._last_fb_dist - dist_remaining) > 0.5:
                self._last_fb_dist = dist_remaining
                self.get_logger().info(
                    f"Nav2 feedback: dist_remaining={dist_remaining:.2f}m, "
                    f"time={nav_time:.1f}s, recoveries={n_recoveries}, "
                    f"accumulated={self._nav_accumulated_dist:.1f}m"
                )

            # â”€â”€ åˆ›æ–°3+4: VoI é©±åŠ¨çš„è¿ç»­è°ƒåº¦ (BA-HSG Â§3.4.4) â”€â”€
            if (self._continuous_reperception
                    and self._state == PlannerState.NAVIGATING
                    and self._current_goal
                    and self._is_semantic_target(self._current_goal.target_label)):

                if self._voi_enabled:
                    # VoI è°ƒåº¦: ä¿¡æ¯ä»·å€¼é©±åŠ¨å†³ç­–
                    voi_state = self._build_voi_state(dist_remaining)
                    voi_action = self._voi_scheduler.decide(voi_state)

                    if voi_action == SchedulerAction.REPERCEIVE:
                        self._last_reperception_dist = self._nav_accumulated_dist
                        self._last_voi_reperception_time = time.time()
                        self._trigger_continuous_reperception()
                    elif voi_action == SchedulerAction.SLOW_REASON:
                        self._last_voi_slow_time = time.time()
                        self._trigger_voi_slow_reason()
                else:
                    # å›é€€: å›ºå®š 2m è§¦å‘
                    dist_since_last = self._nav_accumulated_dist - self._last_reperception_dist
                    if dist_since_last >= self._reperception_interval_m:
                        self._last_reperception_dist = self._nav_accumulated_dist
                        self._trigger_continuous_reperception()

            # æ£€æµ‹å¼‚å¸¸: æ¢å¤æ¬¡æ•°è¿‡å¤š â†’ å¯èƒ½å¡ä½
            if n_recoveries > 3:
                self.get_logger().warn(
                    f"Nav2 too many recoveries ({n_recoveries}), may be stuck"
                )

            # è¶…æ—¶æ£€æµ‹ (Nav2 è‡ªèº«ä¹Ÿæœ‰, è¿™é‡ŒåšåŒé‡ä¿é™©)
            if nav_time > self._nav2_action_timeout:
                self.get_logger().warn(
                    f"Nav2 navigation timeout ({nav_time:.0f}s > {self._nav2_action_timeout:.0f}s)"
                )
                if self._nav2_goal_handle is not None:
                    self._nav2_goal_handle.cancel_goal_async()

        except Exception as e:
            self.get_logger().debug(f"Nav2 feedback parse error: {e}")

    def _trigger_continuous_reperception(self):
        """
        åˆ›æ–°3: å¯¼èˆªä¸­è¿ç»­ Re-perceptionã€‚
        
        è§¦å‘æ¡ä»¶: å¯¼èˆªä¸­æ¯ç§»åŠ¨ reperception_interval_m ç±³ã€‚
        è¡Œä¸º: 
          1. ç”¨å½“å‰åœºæ™¯å›¾åˆ·æ–°ç›®æ ‡ credibility
          2. å¦‚æœ credibility è¿‡ä½, å–æ¶ˆå½“å‰å¯¼èˆªå¹¶è½¬æ¢ç´¢
          3. å¦‚æœå‘ç°æ›´è¿‘/æ›´å¥½çš„åŒ¹é…, æ›´æ–°å¯¼èˆªç›®æ ‡
        """
        if not self._current_goal:
            return

        self.get_logger().info(
            f"Continuous re-perception triggered at "
            f"{self._nav_accumulated_dist:.1f}m"
        )

        async def _do_reperception():
            try:
                accepted = await self._sgnav_reperception_check(
                    self._current_goal, force_vision_on_arrival=False
                )
                if not accepted:
                    self.get_logger().warn(
                        "Continuous re-perception rejected target, "
                        "cancelling navigation"
                    )
                    # å–æ¶ˆå½“å‰ Nav2 goal
                    if self._nav2_goal_handle is not None and self._nav2_goal_active:
                        try:
                            self._nav2_goal_handle.cancel_goal_async()
                        except Exception:
                            pass
                    # è½¬æ¢ç´¢
                    self._subgoal_failed(
                        "Continuous re-perception: target no longer credible"
                    )
                else:
                    self.get_logger().debug(
                        "Continuous re-perception: target still credible"
                    )
            except Exception as e:
                self.get_logger().debug(
                    f"Continuous re-perception error (non-fatal): {e}"
                )

        self._schedule_async(_do_reperception())

    def _build_voi_state(self, distance_remaining: float) -> SchedulerState:
        """æ„å»º VoI è°ƒåº¦å™¨è¾“å…¥çŠ¶æ€ (BA-HSG Â§3.4.4)ã€‚"""
        import json as _json

        # ä»åœºæ™¯å›¾æå–ç›®æ ‡ä¿¡å¿µä¿¡æ¯
        target_cred = 0.5
        target_exist = 0.6
        target_var = 1.0
        match_count = 0
        total_objects = 0

        if self._latest_scene_graph and self._current_goal:
            try:
                sg = _json.loads(self._latest_scene_graph)
                objects = sg.get("objects", [])
                total_objects = len(objects)
                target_label = (self._current_goal.target_label or "").lower()
                for obj in objects:
                    label = str(obj.get("label", "")).lower()
                    if target_label and (target_label in label or label in target_label):
                        match_count += 1
                        belief = obj.get("belief", {})
                        if isinstance(belief, dict):
                            target_cred = max(target_cred, belief.get("credibility", 0.5))
                            target_exist = max(target_exist, belief.get("P_exist", 0.6))
                            sigma = belief.get("sigma_pos", 1.0)
                            target_var = min(target_var, sigma * sigma)
            except Exception:
                pass

        return SchedulerState(
            target_credibility=target_cred,
            target_existence_prob=target_exist,
            target_position_var=target_var,
            match_count=match_count,
            total_objects=total_objects,
            distance_to_goal=distance_remaining,
            nav_accumulated_dist=self._nav_accumulated_dist,
            distance_since_last_reperception=(
                self._nav_accumulated_dist - self._last_reperception_dist
            ),
            slow_reason_count=getattr(self, "_voi_slow_count", 0),
            reperception_count=getattr(self, "_voi_rep_count", 0),
            time_elapsed=time.time() - getattr(self, "_episode_start_time", time.time()),
            last_reperception_time=self._last_voi_reperception_time,
            last_slow_reason_time=self._last_voi_slow_time,
        )

    def _trigger_voi_slow_reason(self) -> None:
        """VoI è°ƒåº¦: è§¦å‘æ…¢æ¨ç†é‡åˆ¤å®š (BA-HSG Â§3.4.4)ã€‚"""
        if not self._current_goal or not self._current_instruction:
            return

        self.get_logger().info(
            "ğŸ§  VoI slow-reason triggered at %.1fm",
            self._nav_accumulated_dist,
        )
        self._voi_slow_count = getattr(self, "_voi_slow_count", 0) + 1

        async def _do_slow_reason():
            try:
                result = await self._resolver.resolve(
                    instruction=self._current_instruction,
                    scene_graph_json=self._latest_scene_graph,
                    robot_position=self._robot_position,
                    language=self._current_language,
                    clip_encoder=getattr(self, "_clip_encoder", None),
                )
                if result.is_valid and result.action == "navigate":
                    if result.confidence > self._current_goal.confidence + 0.1:
                        self.get_logger().info(
                            "ğŸ§  VoI slow-reason found better target: '%s' "
                            "(conf=%.2f > %.2f)",
                            result.target_label,
                            result.confidence,
                            self._current_goal.confidence,
                        )
                        # å–æ¶ˆå½“å‰å¯¼èˆªå¹¶åˆ‡æ¢åˆ°æ–°ç›®æ ‡
                        if self._nav2_goal_handle and self._nav2_goal_active:
                            try:
                                self._nav2_goal_handle.cancel_goal_async()
                            except Exception:
                                pass
                        self._current_goal = result
                        # é‡æ–°å‘é€ Nav2 ç›®æ ‡
                        from geometry_msgs.msg import PoseStamped
                        goal_pose = PoseStamped()
                        goal_pose.header.stamp = self.get_clock().now().to_msg()
                        goal_pose.header.frame_id = result.frame_id  # ä½¿ç”¨ç›®æ ‡è§£æå™¨çš„åæ ‡ç³»
                        goal_pose.pose.position.x = result.target_x
                        goal_pose.pose.position.y = result.target_y
                        goal_pose.pose.position.z = result.target_z
                        goal_pose.pose.orientation.w = 1.0
                        self._send_nav2_goal(goal_pose, result.target_label)
                    else:
                        self.get_logger().debug(
                            "VoI slow-reason: no improvement "
                            "(new=%.2f vs current=%.2f)",
                            result.confidence, self._current_goal.confidence,
                        )
            except Exception as e:
                self.get_logger().debug(f"VoI slow-reason error: {e}")

        self._schedule_async(_do_slow_reason())

    def _nav2_result_callback(self, future):
        """
        Nav2 å¯¼èˆªå®Œæˆ/å¤±è´¥ç»“æœå›è°ƒ (B5 æ ¸å¿ƒ)ã€‚

        æ ¹æ®ç»“æœç è§¦å‘å­ç›®æ ‡å®Œæˆ/å¤±è´¥:
          - STATUS_SUCCEEDED (4): åˆ°è¾¾ç›®æ ‡ â†’ _subgoal_completed()
          - STATUS_ABORTED (6):   å¯¼èˆªå¤±è´¥ â†’ _subgoal_failed()
          - STATUS_CANCELED (5):  è¢«å–æ¶ˆ â†’ ä¸è§¦å‘ (å¯èƒ½æ˜¯æˆ‘ä»¬è‡ªå·±å–æ¶ˆçš„)
        """
        self._nav2_goal_active = False

        try:
            result = future.result()
            status = result.status
        except Exception as e:
            self.get_logger().error(f"Nav2 result error: {e}")
            self._subgoal_failed(f"Nav2 result exception: {e}")
            return

        # rclpy action status codes
        STATUS_SUCCEEDED = 4
        STATUS_CANCELED = 5
        STATUS_ABORTED = 6

        if status == STATUS_SUCCEEDED:
            self.get_logger().info("Nav2: Navigation succeeded")
            # å·²åˆ°è¾¾ â€” GAP: åˆ°è¾¾å Re-perception (è¿‘è·ç¦»é‡æ£€æµ‹éªŒè¯, SG-Nav æ ¸å¿ƒ)
            if self._state == PlannerState.NAVIGATING:
                if (self._current_goal
                        and self.get_parameter("exploration.sgnav.arrival_reperception").value
                        and self._is_semantic_target(self._current_goal.target_label)):
                    self._schedule_async(self._arrival_reperception_then_complete())
                    return
                self._subgoal_completed()
            elif self._state == PlannerState.EXPLORING:
                self.get_logger().info("Nav2: Exploration point reached, re-resolving...")
                self._subgoal_completed()
            elif self._state == PlannerState.APPROACHING:
                self.get_logger().info("Nav2: Approach complete")
                self._subgoal_completed()
            elif self._state == PlannerState.BACKTRACKING:
                self.get_logger().info("Nav2: Backtrack complete")
                self._subgoal_completed()
        elif status == STATUS_ABORTED:
            self.get_logger().warn("Nav2: Navigation aborted (failed to reach goal)")
            self._subgoal_failed("Nav2 navigation aborted")
        elif status == STATUS_CANCELED:
            self.get_logger().info("Nav2: Navigation canceled")
            # ä¸è§¦å‘ subgoal failure, å¯èƒ½æ˜¯æˆ‘ä»¬ä¸»åŠ¨å–æ¶ˆ
        else:
            self.get_logger().warn(f"Nav2: Unexpected status {status}")
            self._subgoal_failed(f"Nav2 unexpected status: {status}")

    def _apply_implicit_fsm_transition(self, result: GoalResult) -> GoalResult:
        """ä½¿ç”¨éšå¼ FSM é¢„æµ‹ mission/search çŠ¶æ€å¹¶è¦†ç›–åŠ¨ä½œå†³ç­–ã€‚"""
        obs = self._build_implicit_fsm_observation(result)
        pred = self._implicit_fsm.predict(obs)
        if pred is None:
            return result

        self._fsm_mission_state = pred.mission_state_out
        self._fsm_search_state = pred.search_state_out

        confidence_state = float(np.max(pred.state_prob))
        reason = (
            f"implicit_fsm: mission={pred.mission_state_out}, "
            f"search={pred.search_state_out}, p={confidence_state:.2f}, "
            f"motion={pred.motion_vector.round(2).tolist()}"
        )
        if result.reasoning:
            result.reasoning = f"{result.reasoning} | {reason}"
        else:
            result.reasoning = reason

        # LOVON 4-state æ˜ å°„åˆ°å½“å‰ planner åŠ¨ä½œ
        if pred.mission_state_out in ("searching_1", "searching_0"):
            result.action = "explore"
            result.path = f"{result.path}+implicit" if result.path else "implicit"
            result.is_valid = True

            # ç”Ÿæˆä¸€ä¸ªçŸ­ç¨‹æ¢ç´¢èˆªç‚¹, åç»­ä»ä¼šèµ° SG-Nav/frontier/LLM æ¢ç´¢é“¾
            if self._robot_position is not None:
                step = max(0.5, float(self._step_distance))
                direction = 1.0 if pred.mission_state_out == "searching_1" else -1.0
                vx = float(np.clip(pred.motion_vector[0], -1.0, 1.0))
                wz = float(np.clip(pred.motion_vector[2], -1.0, 1.0))

                result.target_x = self._robot_position["x"] + step * (0.6 * vx)
                result.target_y = self._robot_position["y"] + step * (0.6 * direction + 0.4 * wz)
                result.target_z = self._robot_position.get("z", 0.0)
                result.target_label = f"implicit_fsm:{pred.mission_state_out}"

            result.confidence = max(float(result.confidence), confidence_state)

        elif pred.mission_state_out == "success":
            result.action = "navigate"
            result.confidence = max(float(result.confidence), 0.95)
            result.path = f"{result.path}+implicit" if result.path else "implicit"

        elif pred.mission_state_out == "running":
            if result.action not in ("navigate", "explore"):
                result.action = "navigate"
            result.path = f"{result.path}+implicit" if result.path else "implicit"

        return result

    def _build_implicit_fsm_observation(self, result: GoalResult) -> ImplicitFSMObservation:
        """æ„é€ éšå¼ FSM è¾“å…¥ç‰¹å¾ã€‚"""
        predicted_object, conf, object_xyn, object_whn = self._extract_detection_for_implicit_fsm(
            result.target_label or self._current_instruction or ""
        )

        return ImplicitFSMObservation(
            mission_instruction_0=self._fsm_prev_instruction or (self._current_instruction or ""),
            mission_instruction_1=self._current_instruction or "",
            mission_object_1=result.target_label or (self._current_instruction or ""),
            predicted_object=predicted_object,
            confidence=max(float(result.confidence), conf),
            object_xyn=np.asarray(object_xyn, dtype=np.float64),
            object_whn=np.asarray(object_whn, dtype=np.float64),
            mission_state_in=self._fsm_mission_state,
            search_state_in=self._fsm_search_state,
        )

    def _extract_detection_for_implicit_fsm(self, target_text: str):
        """ä»æœ€æ–°åœºæ™¯å›¾æå–éšå¼ FSM æ‰€éœ€æ£€æµ‹ç‰¹å¾ã€‚"""
        try:
            sg = json.loads(self._latest_scene_graph)
        except (json.JSONDecodeError, TypeError):
            return "NULL", 0.0, np.array([0.5, 0.5]), np.array([0.0, 0.0])

        objects = sg.get("objects", [])
        if not isinstance(objects, list) or not objects:
            return "NULL", 0.0, np.array([0.5, 0.5]), np.array([0.0, 0.0])

        tokens = [
            t for t in re.findall(r"[A-Za-z0-9_]+|[\u4e00-\u9fff]{1,4}", target_text.lower())
            if len(t) > 1
        ]

        best_obj = None
        best_score = -1.0
        for obj in objects:
            if not isinstance(obj, dict):
                continue
            label = str(obj.get("label", "")).lower()
            lexical = 0.0
            for t in tokens:
                if t in label or label in t:
                    lexical = max(lexical, 1.0)

            det_score = 0.0
            try:
                det_score = float(obj.get("score", 0.0))
            except (TypeError, ValueError):
                pass

            score = 0.7 * lexical + 0.3 * det_score
            if score > best_score:
                best_score = score
                best_obj = obj

        if best_obj is None or best_score < 0.25:
            return "NULL", 0.0, np.array([0.5, 0.5]), np.array([0.0, 0.0])

        label = str(best_obj.get("label", "NULL"))
        try:
            conf = float(best_obj.get("score", 0.0))
        except (TypeError, ValueError):
            conf = 0.0

        # scene_graph ä¸­é€šå¸¸æ— å½’ä¸€åŒ– bbox, ç”¨ç›¸å¯¹æ–¹ä½/è·ç¦»ä¼°è®¡ xyn å’Œå°ºå¯¸ proxy
        cxn, cyn = 0.5, 0.5
        size_proxy = min(1.0, max(0.0, conf))
        if self._robot_position is not None:
            pos = best_obj.get("position", {})
            if isinstance(pos, dict) and "x" in pos and "y" in pos:
                try:
                    dx = float(pos.get("x", 0.0)) - self._robot_position["x"]
                    dy = float(pos.get("y", 0.0)) - self._robot_position["y"]
                    dist = math.sqrt(dx * dx + dy * dy)
                    angle = math.atan2(dy, dx)
                    cxn = 0.5 + 0.5 * math.sin(angle)
                    cyn = 0.5 - 0.5 * math.cos(angle)
                    size_proxy = min(1.0, 1.0 / (1.0 + max(dist, 0.0)))
                except (TypeError, ValueError):
                    pass

        whn = np.array([size_proxy, size_proxy], dtype=np.float64)
        xyn = np.array([float(np.clip(cxn, 0.0, 1.0)), float(np.clip(cyn, 0.0, 1.0))])
        return label, float(np.clip(conf, 0.0, 1.0)), xyn, whn

    async def _handle_explore_result(self, result: GoalResult):
        """å¤„ç†æ¢ç´¢ç»“æœ (F7: Fast+Slow éƒ½å¤±è´¥æ—¶æœ‰ fallback)ã€‚"""
        if not self._explore_enabled or not self._current_explore_if_unknown:
            self.get_logger().info("Exploration disabled, failing")
            self._set_state(PlannerState.FAILED)
            return

        if self._explore_count >= self._max_explore_steps:
            self.get_logger().info("Max exploration steps reached")
            # F7: è¶…é™åä¸ç›´æ¥ FAIL, å°è¯• BACKTRACK å›èµ·ç‚¹
            backtrack_pos = self._topo_memory.get_backtrack_position(
                steps_back=self._explore_count
            )
            if backtrack_pos is not None:
                self.get_logger().info("Max explore reached, backtracking to start")
                cmd = self._action_executor.generate_backtrack_command(backtrack_pos)
                self._publish_goal_from_command(cmd)
                self._set_state(PlannerState.BACKTRACKING)
            else:
                self._set_state(PlannerState.FAILED)
            return

        self._explore_count += 1

        if self._robot_position:
            # SG-Nav: å­å›¾æ¨ç† + frontier æ¦‚ç‡æ’å€¼
            if self._exploration_strategy == "sg_nav":
                sgnav_result = await self._generate_sgnav_waypoint()
                if sgnav_result is not None and sgnav_result.is_valid:
                    self._current_goal = sgnav_result
                    self._publish_exploration_goal(sgnav_result, source="sg_nav")
                    return

                self.get_logger().debug(
                    "SG-Nav exploration unavailable, fallback to frontier/llm"
                )

                # SG-Nav fallback 1: çº¯ frontier
                frontier_result = self._generate_frontier_waypoint()
                if frontier_result is not None and frontier_result.is_valid:
                    self._current_goal = frontier_result
                    self._publish_exploration_goal(frontier_result, source="frontier_fallback")
                    return

            # ä¼˜å…ˆä½¿ç”¨ Frontier è¯„åˆ†æ¢ç´¢ (MTU3D é£æ ¼é—­ç¯)
            if self._exploration_strategy == "frontier":
                frontier_result = self._generate_frontier_waypoint()
                if frontier_result is not None and frontier_result.is_valid:
                    self._current_goal = frontier_result
                    self._publish_exploration_goal(frontier_result, source="frontier")
                    return

                self.get_logger().debug(
                    "Frontier exploration unavailable, fallback to LLM exploration"
                )

            # Fallback: LLM å»ºè®®æ¢ç´¢æ–¹å‘
            explore_result = await self._resolver.generate_exploration_waypoint(
                instruction=self._current_instruction,
                robot_position=self._robot_position,
                step_distance=self._step_distance,
                language=self._current_language,
            )

            if explore_result.is_valid:
                self._current_goal = explore_result
                self._publish_exploration_goal(explore_result, source="llm")
            else:
                self._set_state(PlannerState.FAILED)

    async def _generate_sgnav_waypoint(self) -> Optional[GoalResult]:
        """ç”¨ SG-Nav å­å›¾æ¨ç† + frontier æ’å€¼ç”Ÿæˆæ¢ç´¢èˆªç‚¹ã€‚"""
        if self._robot_position is None:
            return None

        robot_xy = np.array([
            self._robot_position["x"],
            self._robot_position["y"],
        ], dtype=np.float64)

        frontiers = self._frontier_scorer.extract_frontiers(robot_xy)
        if not frontiers:
            return None

        scene_objects, scene_relations = extract_frontier_scene_data(self._latest_scene_graph)
        scored_frontiers = self._frontier_scorer.score_frontiers(
            instruction=self._current_instruction or "",
            robot_position=robot_xy,
            visited_positions=self._topo_memory.visited_positions,
            scene_objects=scene_objects,
            scene_relations=scene_relations,
        )

        llm_chat = self._resolver._call_with_fallback if self._sgnav_use_llm_reasoning else None
        selection: Optional[FrontierSelection] = await self._sgnav_reasoner.select_frontier(
            instruction=self._current_instruction or "",
            scene_graph_json=self._latest_scene_graph,
            robot_position=self._robot_position,
            frontiers=scored_frontiers,
            language=self._current_language,
            llm_chat=llm_chat,
        )

        if selection is None:
            return None
        if selection.score < self._frontier_score_threshold:
            return None

        best = selection.frontier
        return GoalResult(
            action="explore",
            target_x=float(best.center_world[0]),
            target_y=float(best.center_world[1]),
            target_z=float(self._robot_position.get("z", 0.0)),
            target_label=f"sgnav_frontier:{best.direction_label}",
            confidence=float(selection.score),
            reasoning=selection.reasoning,
            is_valid=True,
            path="sg_nav",
        )

    def _is_semantic_target(self, target_label: Optional[str]) -> bool:
        """æ˜¯å¦ä¸ºè¯­ä¹‰ç›®æ ‡ (éæ¢ç´¢ç‚¹)ï¼Œéœ€åšåˆ°è¾¾å Re-perceptionã€‚"""
        if not target_label or not isinstance(target_label, str):
            return False
        t = target_label.strip().lower()
        if t.startswith("sgnav_frontier:") or t.startswith("implicit_fsm:"):
            return False
        return True

    async def _arrival_reperception_then_complete(self):
        """
        åˆ°è¾¾å Re-perception + BA-HSG è´å¶æ–¯éªŒè¯ (Â§3.4.3)ã€‚
        
        æµç¨‹:
          1. ä¼ ç»Ÿ re-perception æ£€æŸ¥ (è§†è§‰+å¯ä¿¡åº¦)
          2. BA-HSG: è´å¶æ–¯æ›´æ–° â†’ å¦‚æœç›®æ ‡è¢«æ‹’ç», è‡ªåŠ¨é‡é€‰ä¸‹ä¸€å€™é€‰
          3. å¦‚æœå¤šå‡è®¾ç®¡ç†å™¨æœ‰é‡é€‰ç»“æœ â†’ å¯¼èˆªåˆ°æ–°å€™é€‰
          4. å¦åˆ™èµ°ä¼ ç»Ÿçš„æ¢ç´¢å›é€€
        """
        if not self._current_goal:
            self._subgoal_completed()
            return
        accepted = await self._sgnav_reperception_check(
            self._current_goal, force_vision_on_arrival=True
        )
        if accepted:
            self._subgoal_completed()
        else:
            # BA-HSG: å¤šå‡è®¾è´å¶æ–¯é‡é€‰
            candidate_id = getattr(self._current_goal, "candidate_id", -1)
            if candidate_id >= 0 and hasattr(self._resolver, "verify_and_reselect"):
                robot_pos = None
                if self._robot_position:
                    robot_pos = [
                        self._robot_position.get("x", 0),
                        self._robot_position.get("y", 0),
                    ]
                new_goal = self._resolver.verify_and_reselect(
                    object_id=candidate_id,
                    detected=False,
                    clip_sim=0.3,
                    robot_position=robot_pos,
                )
                if new_goal and new_goal.is_valid:
                    self.get_logger().info(
                        "ğŸ”„ BA-HSG reselect at arrival: '%s' â†’ '%s'",
                        self._current_goal.target_label,
                        new_goal.target_label,
                    )
                    self._current_goal = new_goal
                    from geometry_msgs.msg import PoseStamped
                    goal_pose = PoseStamped()
                    goal_pose.header.stamp = self.get_clock().now().to_msg()
                    goal_pose.header.frame_id = new_goal.frame_id  # ä½¿ç”¨æ–°ç›®æ ‡çš„åæ ‡ç³»
                    goal_pose.pose.position.x = new_goal.target_x
                    goal_pose.pose.position.y = new_goal.target_y
                    goal_pose.pose.position.z = new_goal.target_z
                    goal_pose.pose.orientation.w = 1.0
                    self._send_nav2_goal(goal_pose, new_goal.target_label)
                    return

            self.get_logger().warn(
                "Arrival re-perception rejected target, switching to exploration"
            )
            await self._handle_explore_result(
                GoalResult(
                    action="explore",
                    confidence=0.1,
                    reasoning="Arrival re-perception: target not confirmed at close range",
                    is_valid=True,
                    path="arrival_reperception",
                )
            )

    async def _sgnav_reperception_check(
        self, result: GoalResult, force_vision_on_arrival: bool = False
    ) -> bool:
        """
        SG-Nav graph-based re-perception:
        å½“ç›®æ ‡å¯ä¿¡åº¦è¿‡ä½æ—¶æ‹’ç»è¯¥ç›®æ ‡å¹¶ç»§ç»­æ¢ç´¢ã€‚
        force_vision_on_arrival: åˆ°è¾¾åå¼ºåˆ¶åšè§†è§‰éªŒè¯ (è¿‘è·ç¦»é‡æ£€æµ‹)ã€‚
        """
        if not result.target_label:
            return True

        run_vision = (
            self._vision_enabled
            and self._latest_image_base64
            and (
                force_vision_on_arrival
                or result.confidence < self._confidence_threshold
            )
        )
        confirmed_visible = False
        if run_vision:
            try:
                vg = await self._resolver.vision_grounding(
                    instruction=result.target_label,
                    scene_graph_json=self._latest_scene_graph,
                    image_base64=self._latest_image_base64,
                    language=self._current_language,
                )
                confirmed_visible = bool(
                    vg.get("target_visible", False)
                    and float(vg.get("confidence", 0.0)) > self._vision_verify_threshold
                )
            except Exception as e:
                self.get_logger().debug(f"SG-Nav re-perception vision check failed: {e}")

        reject, cred, reason = self._sgnav_reasoner.evaluate_target_credibility(
            target_label=result.target_label,
            scene_graph_json=self._latest_scene_graph,
            path_confidence=result.confidence,
            confirmed_visible=confirmed_visible,
        )

        if reject:
            self.get_logger().warn(
                f"SG-Nav re-perception reject '{result.target_label}': {reason}"
            )
            return False

        self.get_logger().debug(
            f"SG-Nav re-perception accept '{result.target_label}': cred={cred:.2f}; {reason}"
        )
        return True

    def _generate_frontier_waypoint(self) -> Optional[GoalResult]:
        """ç”¨ Frontier è¯„åˆ†å™¨ç”Ÿæˆæ¢ç´¢èˆªç‚¹ã€‚"""
        if self._robot_position is None:
            return None
        return generate_frontier_goal(
            frontier_scorer=self._frontier_scorer,
            instruction=self._current_instruction or "",
            robot_position=self._robot_position,
            visited_positions=self._topo_memory.visited_positions,
            scene_graph_json=self._latest_scene_graph,
            score_threshold=self._frontier_score_threshold,
        )

    def _publish_exploration_goal(self, explore_result: GoalResult, source: str):
        """å‘å¸ƒæ¢ç´¢èˆªç‚¹ (B5: ä¼˜å…ˆ Nav2 action)ã€‚"""
        goal = PoseStamped()
        goal.header.stamp = self.get_clock().now().to_msg()
        goal.header.frame_id = explore_result.frame_id  # ä½¿ç”¨æ¢ç´¢ç»“æœçš„åæ ‡ç³»
        goal.pose.position.x = explore_result.target_x
        goal.pose.position.y = explore_result.target_y
        goal.pose.position.z = explore_result.target_z
        goal.pose.orientation.w = 1.0

        if self._use_nav2_action and self._nav2_action_client is not None:
            self._send_nav2_goal(goal, f"explore:{source}")
        else:
            self._pub_goal.publish(goal)
        self._set_state(PlannerState.EXPLORING)

        self.get_logger().info(
            f"Exploration waypoint ({source}) #{self._explore_count}: "
            f"({explore_result.target_x:.2f}, {explore_result.target_y:.2f}) "
            f"conf={explore_result.confidence:.2f}, reason: {explore_result.reasoning}"
        )

    # ================================================================
    #  ç›‘æ§
    # ================================================================

    def _monitor_callback(self):
        """
        å®šæœŸç›‘æ§ä»»åŠ¡çŠ¶æ€ã€‚

        èŒè´£:
          1. è¶…æ—¶æ£€æµ‹
          2. åˆ°è¾¾æ£€æµ‹ (NAVIGATING / EXPLORING / APPROACHING / BACKTRACKING)
          3. æ‹“æ‰‘è®°å¿†æ›´æ–° (L3MVN)
          4. å‘å¸ƒçŠ¶æ€
        """
        if self._state in (
            PlannerState.IDLE, PlannerState.COMPLETED,
            PlannerState.FAILED, PlannerState.CANCELLED,
        ):
            return

        # â”€â”€ æ‹“æ‰‘è®°å¿†æ›´æ–° (L3MVN) â”€â”€
        if self._robot_position:
            visible_labels = []
            try:
                sg = json.loads(self._latest_scene_graph)
                visible_labels = [
                    obj["label"] for obj in sg.get("objects", [])[:10]
                ]
            except (json.JSONDecodeError, TypeError, KeyError) as e:
                self.get_logger().debug(f"Scene graph parse in monitor: {e}")

            self._topo_memory.update_position(
                position=np.array([
                    self._robot_position["x"],
                    self._robot_position["y"],
                    self._robot_position.get("z", 0.0),
                ]),
                visible_labels=visible_labels,
                # D7: ç»“æ„åŒ–æˆªæ–­ â€” åªä¿ç•™é™„è¿‘ç‰©ä½“çš„æ ‡ç­¾
                scene_snapshot=json.dumps(
                    {"nearby_labels": visible_labels[:5]}, ensure_ascii=False
                ),
            )

        # â”€â”€ è¶…æ—¶æ£€æµ‹ â”€â”€
        if self._task_start_time > 0:
            elapsed = time.time() - self._task_start_time
            if elapsed > self._instruction_timeout:
                self.get_logger().warn(
                    f"Semantic nav timeout ({elapsed:.0f}s > "
                    f"{self._instruction_timeout:.0f}s)"
                )
                self._set_state(PlannerState.FAILED)
                return

        # â”€â”€ åˆ°è¾¾æ£€æµ‹ â”€â”€
        arrival_states = (
            PlannerState.NAVIGATING, PlannerState.EXPLORING,
            PlannerState.APPROACHING, PlannerState.BACKTRACKING,
        )
        if self._state in arrival_states:
            if self._robot_position and self._current_goal:
                dist = math.sqrt(
                    (self._current_goal.target_x - self._robot_position["x"]) ** 2
                    + (self._current_goal.target_y - self._robot_position["y"]) ** 2
                )

                if dist < self._arrival_radius:
                    if self._state == PlannerState.NAVIGATING:
                        self.get_logger().info(
                            f"Arrived at target: {self._current_goal.target_label}"
                        )
                        self._subgoal_completed()

                    elif self._state == PlannerState.EXPLORING:
                        self.get_logger().info(
                            f"Arrived at exploration point {self._explore_count}, "
                            f"re-resolving..."
                        )
                        self._subgoal_completed()

                    elif self._state == PlannerState.APPROACHING:
                        self.get_logger().info("Approach complete")
                        self._subgoal_completed()

                    elif self._state == PlannerState.BACKTRACKING:
                        self.get_logger().info("Backtrack complete")
                        self._subgoal_completed()

        # å‘å¸ƒçŠ¶æ€
        self._publish_status()

    # ================================================================
    #  çŠ¶æ€ç®¡ç†
    # ================================================================

    def _publish_goal_from_command(self, cmd: ActionCommand):
        """å°† ActionCommand è½¬ä¸º PoseStamped å‘å¸ƒ (B5: ä¼˜å…ˆ Nav2 action)ã€‚"""
        goal = PoseStamped()
        goal.header.stamp = self.get_clock().now().to_msg()
        goal.header.frame_id = cmd.frame_id
        goal.pose.position.x = cmd.target_x
        goal.pose.position.y = cmd.target_y
        goal.pose.position.z = cmd.target_z

        goal.pose.orientation.z = math.sin(cmd.target_yaw / 2)
        goal.pose.orientation.w = math.cos(cmd.target_yaw / 2)

        if self._use_nav2_action and self._nav2_action_client is not None:
            self._send_nav2_goal(goal, cmd.command_type)
        else:
            self._pub_goal.publish(goal)
        self._current_action_cmd = cmd

    def _set_state(self, new_state: PlannerState):
        """æ›´æ–°çŠ¶æ€ã€‚"""
        old_state = self._state
        self._state = new_state
        if old_state != new_state:
            self.get_logger().info(f"State: {old_state.value} â†’ {new_state.value}")

    def _publish_status(self):
        """å‘å¸ƒå½“å‰çŠ¶æ€ (å«ä»»åŠ¡è®¡åˆ’è¿›åº¦)ã€‚"""
        status = {
            "state": self._state.value,
            "instruction": self._current_instruction or "",
            "exploration_strategy": self._exploration_strategy,
            "target_label": (
                self._current_goal.target_label if self._current_goal else ""
            ),
            "confidence": (
                round(self._current_goal.confidence, 3) if self._current_goal else 0
            ),
            "is_exploring": self._state == PlannerState.EXPLORING,
            "explore_count": self._explore_count,
            "replan_count": self._replan_count,
            "elapsed_sec": round(time.time() - self._task_start_time, 1)
            if self._task_start_time > 0
            else 0,
            "plan": self._current_plan.to_dict() if self._current_plan else None,
            "topo_memory": {
                "nodes": len(self._topo_memory.nodes),
            },
            "frontier_count": len(getattr(self._frontier_scorer, "_frontiers", [])),
            "sgnav": {
                "credibility_count": len(self._sgnav_reasoner.target_credibility),
            },
            "fsm": {
                "mode": self._fsm_mode,
                "mission_state": self._fsm_mission_state,
                "search_state": self._fsm_search_state,
                "implicit_ready": self._implicit_fsm.is_ready,
            },
        }

        msg = String()
        msg.data = json.dumps(status, ensure_ascii=False)
        self._pub_status.publish(msg)

    # ================================================================
    #  ç”Ÿå‘½å‘¨æœŸ
    # ================================================================

    def destroy_node(self):
        """æ¸…ç†ã€‚"""
        self._loop.call_soon_threadsafe(self._loop.stop)
        self._async_thread.join(timeout=3.0)
        super().destroy_node()


def main(args=None):
    rclpy.init(args=args)
    node = SemanticPlannerNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()
